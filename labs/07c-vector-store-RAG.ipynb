{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c479f97-7ce3-4c31-809f-5ad0e7b7fca3",
   "metadata": {},
   "source": [
    "# <center>Critical AI</center>\n",
    "<center>ENGL 54.41</center>\n",
    "<center>Dartmouth College</center>\n",
    "<center>Winter 2026</center>\n",
    "<pre>Created: 02/18/2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e172130-3203-48f6-9300-75d3f81551ff",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "\n",
    "We want to run this in a GPU environment (e.g., T4 or better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61683abc-1dfc-48c8-a1c7-2514ea7b98bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install FAISS first\n",
    "!pip install faiss-cpu > /dev/null 2>&1\n",
    "from openai import OpenAI\n",
    "import torch\n",
    "import faiss\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7300342-0127-4322-8ba5-9286c83492d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"anthropic.claude-opus-4-6\"\n",
    "api_key = \"API_KEY_GOES_HERE\"\n",
    "\n",
    "client = OpenAI(base_url=\"https://chat.dartmouth.edu/api\", \n",
    "                api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8350fa-3e5f-409f-8db8-6181a13dea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell of code will determine if we have an accelerator for running\n",
    "# our neural networks.\n",
    "# mps == Apple Silicon device (MX series of Macbooks)\n",
    "# cuda == Compute Unified Device Architecture is a toolkit from Nvidia and means we have a GPU\n",
    "# cpu == Just using the general-purpose CPU for our calculations\n",
    "\n",
    "if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('Using device: {0}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fd4b2f-442c-4285-8db4-a5b8454b6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download LayupList data\n",
    "!wget -O old_reviews.json https://raw.githubusercontent.com/jeddobson/ENGL64.05-22F/refs/heads/main/data/LayupList/old_reviews.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0e2dae-81f5-40d2-b6f7-bef47ac8b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open older format reviews and extract comments\n",
    "reviews = json.loads(open(\"old_reviews.json\").read())\n",
    "reviews_text= [r[\"comments\"][\"oldReview\"] for r in reviews if 'comments' in r]\n",
    "# how many did we find?\n",
    "print(\"found {0} reviews\".format(len(reviews_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c32114-2f2a-4942-b9ef-e7f5fd4a5c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a smaller embedding model that will quickly embed all our documents\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbdd4ee-9f32-441c-910a-332a7847d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move model to our accelerator device\n",
    "embedding_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1308c7-1c81-4751-8061-da3bffe2b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create document embeddings with embedding model\n",
    "doc_embeddings = embedding_model.encode(reviews_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfbdac3-cfdd-4702-a062-1b2ddaea532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display number of documents and embedding width\n",
    "doc_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d9197-66ee-492c-abc4-d3f26d93ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build FAISS index\n",
    "index = faiss.IndexFlatL2(doc_embeddings.shape[1])\n",
    "index.add(np.array(doc_embeddings))\n",
    "\n",
    "# this will retrieve five closest neighbors using document similarity\n",
    "def retrieve_documents(query, k=5):\n",
    "    query_embedding = embedding_model.encode([query])[0]\n",
    "    distances, indices = index.search(np.array([query_embedding]), k)\n",
    "    return [reviews_text[i] for i in indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7454b4e1-2a80-46a3-9f0c-4bab6d827758",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I am interested in the very best courses offered in the Spanish Department. Who are the best professors in Spanish?\"\n",
    "query_embedding = embedding_model.encode([query])[0]\n",
    "distances, indices = index.search(np.array([query_embedding]), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c911626e-dc93-4b72-a2a1-e3174086ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Similarity\":distances[0],\n",
    "                   \"Document Idx\":indices[0],\n",
    "                   \"Contents\":[reviews_text[i][:40].replace('\\t','') for i in indices[0]]})\n",
    "df.sort_values(by='Similarity',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e414505e-2f29-44a3-a7a1-f51cbf520c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I am interested in the very best courses offered in the Spanish Department. Who are the best professors in Spanish?\"\n",
    "\n",
    "# Retrieve relevant documents for our query\n",
    "retrieved_docs = retrieve_documents(query,k=25)\n",
    "\n",
    "# Join query with context.\n",
    "context = query + \"\\nCourse Review Data:\\n\" + \"\\n\".join(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8624d886-bf3f-41fa-90a8-3dbf60b928a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae78d7-dcc1-48b8-bd4d-5d9fc61f0532",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = client.chat.completions.create(\n",
    "    model = model_name,\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. You are also a chatbot able to recommend courses to Dartmouth students based on reviews.\" },\n",
    "        {\"role\": \"user\", \"content\": context}\n",
    "    ],\n",
    "    stream = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17f7c03-7aad-4ff0-9402-dfd2e8ed21be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display \"usage\" information. How many tokens were generated? How many did we submit \n",
    "# as part of prompt?\n",
    "output.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff6ff64-f123-44dd-8e91-e6d5f68692af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# message content is the output after the end of the reasoning trace.\n",
    "response = output.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac07d98f-b105-4bb5-b318-ea8dd913d203",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
