{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2169392-3185-408c-add0-7200ca85e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e2be85f-f955-41e1-879e-87d3a0a7c9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('Using device: {0}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244cf92b-dd52-4140-9ec2-b3d53026c239",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Olmo2ForCausalLM(\n",
       "  (model): Olmo2Model(\n",
       "    (embed_tokens): Embedding(100352, 2048, padding_idx=100277)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x Olmo2DecoderLayer(\n",
       "        (self_attn): Olmo2Attention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (q_norm): Olmo2RMSNorm((2048,), eps=1e-06)\n",
       "          (k_norm): Olmo2RMSNorm((2048,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Olmo2MLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (post_attention_layernorm): Olmo2RMSNorm((2048,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Olmo2RMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Olmo2RMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): Olmo2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=100352, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"allenai/OLMo-2-0425-1B-Instruct\"\n",
    "\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "#                                             low_cpu_mem_usage=True,\n",
    "#                                             dtype=torch.bfloat16,\n",
    "#                                             device_map=\"auto\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             device_map=\"auto\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42102dc0-bf36-4049-ae42-fd09b705ea51",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|><|user|>\n",
      "Write a short poem about Eleazar Wheelock, founder of Dartmouth College.\n",
      "by Robert Frost\n",
      "\n",
      "Eleazar Wheelock\n",
      "You founded Dartmouth College,\n",
      "You also taught a bit,\n",
      "And thought a bit,\n",
      "Praised God a bit,\n",
      "And wrote some notes on the Greek language\n",
      "Ponderous and quite precise\n",
      "For your young American pupils,\n",
      "And with a flair for the dramatic\n",
      "Had grand dreams for the college\n",
      "And put those dreams into being\n",
      "A place for youth not just for study\n",
      "\n",
      "Questions are everywhere in the halls\n",
      "Of every great college today,\n",
      "But the first Dartmouth ever stands tall,\n",
      "And Eleazarâ€™s visions, they continue to be.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Write a short poem about Eleazar Wheelock, founder of Dartmouth College.\"\n",
    "max_new_tokens = 128\n",
    "msg = [{\"role\":\"user\",\"content\":input_text}]\n",
    "input_ids = tokenizer.apply_chat_template(msg, \n",
    "                                          return_tensors = \"pt\",\n",
    "                                          add_generation_prompt = False)\n",
    "\n",
    "output = model.generate(input_ids.to(device), \n",
    "                        do_sample=True, \n",
    "                        max_new_tokens = max_new_tokens,\n",
    "                        temperature = 1.0, \n",
    "                        top_p = 0.95)\n",
    "\n",
    "print(tokenizer.decode(output[0], \n",
    "                       skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39528a5a-0cac-458b-8ed3-b1baf6c345a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
