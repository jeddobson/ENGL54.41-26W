{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d95d96-57db-4c5f-9677-7cd781b031ef",
   "metadata": {},
   "source": [
    "# <center>Critical AI</center>\n",
    "<center>ENGL 54.41</center>\n",
    "<center>Dartmouth College</center>\n",
    "<center>Winter 2026</center>\n",
    "<pre>Created: 02/18/2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61683abc-1dfc-48c8-a1c7-2514ea7b98bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7300342-0127-4322-8ba5-9286c83492d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"openai.gpt-oss-120b\"\n",
    "api_key = \"API_KEY_GOES_HERE\"\n",
    "\n",
    "client = OpenAI(base_url=\"https://chat.dartmouth.edu/api\", \n",
    "                api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae78d7-dcc1-48b8-bd4d-5d9fc61f0532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation function -- this will submit our prompt to the API with a system prompt.\n",
    "def generate(prompt):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model = model_name,\n",
    "        temperature = 0.25,\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}],\n",
    "        stream = False)\n",
    "    return chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45778e6f-9a78-49a9-9a26-e05cf111660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Prompting for completion\n",
    "prompt = \"\"\"Instructions: please complete the following text. Use only what you have seen in your training data.\n",
    "\n",
    "The woods are lovely, dark and deep,   \n",
    "But I have promises to keep,\n",
    "\"\"\"\n",
    "\n",
    "output = generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb4dd3c-ad41-467b-a557-49926fceea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display response\n",
    "response = output.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e77ce55-8ba3-4890-bd83-c60fd70a9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Masked Prompting for completion\n",
    "prompt = \"\"\"Instructions: In the following replace [MASK] with the correct word. Use only a single word.\n",
    "Make sure to use only the words found from samples in your training data. You must make a guess, \n",
    "even if you are uncertain.\n",
    "\n",
    "Example: \n",
    "\n",
    "Input: Whenever Richard [MASK] went down town,\n",
    "Output <token>Cory</token>\n",
    "\n",
    "Input: But a caged [MASK] stands on the grave of dreams\n",
    "Output:\"\"\"\n",
    "\n",
    "output = generate(prompt)\n",
    "response = output.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6962ec47-6d84-4785-ad86-c39e97459de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"What is the next token. Provide just a single word. \n",
    "Dartmouth College's mission is to educate promising students and prepare them for a \n",
    "lifetime of learning and responsible\"\"\"\n",
    "output = generate(prompt)\n",
    "response = output.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec8c5e3-dce8-4b01-a3ac-5a61eccb09ba",
   "metadata": {},
   "source": [
    "## Iterative Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d2a35-dba8-4492-995b-5c49ae1608db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define prompt for iteration\n",
    "prompt = \"Write a short story about a student's first year attending Dartmouth College. Use normal paragraph structure. Include experiences and events in each of the three major terms: fall, winter, and spring.\"\n",
    "iterations = 10 \n",
    "\n",
    "# create list to store generated texts.\n",
    "outputs = list()\n",
    "\n",
    "# iterate through and save stories to output list\n",
    "for i in range(iterations):\n",
    "          outputs.append(generate(prompt).choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1a948-f601-4cd7-ada9-485804467bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize and create document-term matrix for modeling\n",
    "vectorizer = CountVectorizer(input='content',\n",
    "                             strip_accents='unicode',\n",
    "                             stop_words='english')\n",
    "dtm = vectorizer.fit_transform(outputs)\n",
    "idx2voc = {v:k for k, v in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e2c7cf-1ce3-40ba-a80b-6b6bc943836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sums = dtm.sum(axis=0)\n",
    "sorted_vocab = [(v, vocab_sums[0, i]) for v, i in vectorizer.vocabulary_.items()]\n",
    "sorted_vocab = sorted(sorted_vocab, key = lambda x: x[1], reverse=True)\n",
    "\n",
    "# display top twenty-five words\n",
    "for i in range(25):\n",
    "    print(sorted_vocab[i][0],\"=>\",sorted_vocab[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a037eaee-b4a9-4f32-b95d-008e5a13c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small helper function to examining presence of specific words\n",
    "def term_debug(term):\n",
    "    if term in vectorizer.vocabulary_:\n",
    "        idx = vectorizer.vocabulary_[term]\n",
    "    else:\n",
    "        print(\"Error: {0} not on vocabulary\".format(term))\n",
    "        return\n",
    "    tc = int(np.sum(dtm,axis=0)[:, idx].item())\n",
    "    tm = float(np.mean(dtm,axis=0)[:, idx].item())\n",
    "    return pd.DataFrame({'Total Count':tc,'Mean Count':tm},  index=[term])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febedc20-6799-4a54-b2e8-31a34cd6b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_debug('library')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce88b4ac-6742-40e7-a399-c4de8b8b5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=0, n_init=\"auto\")\n",
    "kmeans.fit(dtm)\n",
    "\n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_ \n",
    "\n",
    "svd = TruncatedSVD(n_components=2, random_state=0)\n",
    "dtm_svd = svd.fit_transform(dtm)           \n",
    "clusters_svd = svd.transform(centroids)      \n",
    "\n",
    "plt.scatter(dtm_svd[:, 0], dtm_svd[:, 1], c=labels, alpha=0.5)\n",
    "plt.scatter(clusters_svd[:, 0], clusters_svd[:, 1], \n",
    "            marker='o', \n",
    "            s=150, \n",
    "            edgecolor='black')\n",
    "plt.title(\"k-Means Clustering of DTM\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf8fceb-78ee-44b4-be3f-9f8bd9c5711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "for story in outputs:\n",
    "  display(HTML('<div>' + story + '</div>'))\n",
    "  display(HTML('<hr>'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
